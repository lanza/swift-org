//
//  Lexer.swift
//  SwiftOrg
//
//  Created by Xiaoxing Hu on 14/08/16.
//  Copyright Â© 2016 Xiaoxing Hu. All rights reserved.
//

import Foundation

public enum LexerErrors: Error {
  case tokenizeFailed(Int, String)
}

open class Lexer {
  let lines: [String]
  public init(lines theLines: [String]) {
    lines = theLines
  }

  /// Tokenize one line, without considering the context
  ///
  /// - Parameter line: the target line
  /// - Returns: the token
  class func tokenize(line: String) -> Token? {
    defineTokens()
    for td in tokenDescriptors {
      guard let m = line.match(td.pattern, options: td.options) else {
        continue
      }
      return td.generator(m)
    }
    return nil
  }

  func tokenize(cursor: Int = 0, tokens: [TokenInfo] = []) throws -> [TokenInfo]
  {

    if lines.count == cursor { return tokens }
    let line = lines[cursor]

    guard let token = Lexer.tokenize(line: line) else {
      throw LexerErrors.tokenizeFailed(cursor, line)
    }

    return try tokenize(
      cursor: cursor + 1,
      tokens: tokens + [(TokenMeta(raw: line, lineNumber: cursor), token)])
  }
}
