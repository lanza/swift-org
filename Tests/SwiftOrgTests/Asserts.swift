//
//  Asserts.swift
//  SwiftOrg
//
//  Created by Xiaoxing Hu on 15/09/16.
//  Copyright Â© 2016 Xiaoxing Hu. All rights reserved.
//

import XCTest

@testable import SwiftOrg

func expect(
  _ actual: Token, toBe expected: Token,
  file: StaticString = #file, line: UInt = #line
) {
  XCTAssertEqual(
    expected, actual,
    file: file, line: line)
}

func evalListItem(
  _ str: String, indent: Int, text: String?, ordered: Bool,
  checked: Bool? = nil,
  file: StaticString = #file, line: UInt = #line
) {

  let token = Lexer.tokenize(line: str)
  expect(
    token!,
    toBe: .listItem(
      indent: indent, text: text, ordered: ordered, checked: checked),
    file: file, line: line)
}

func evalHorizontalRule(
  _ str: String,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .horizontalRule,
    file: file, line: line)
}

func evalComment(
  _ str: String, text: String,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .comment(text),
    file: file, line: line)
}

func evalBlockEnd(
  _ str: String, type: String,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .blockEnd(name: type),
    file: file, line: line)
}

func evalBlockBegin(
  _ str: String, type: String, params: [String]?,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .blockBegin(name: type, params: params),
    file: file, line: line)
}

func evalHeadline(
  _ str: String, stars: Int, text: String?,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .headline(stars: stars, text: text),
    file: file, line: line)
}

func evalPlanning(
  _ str: String, keyword: String, timestamp: Timestamp?,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!,
    toBe: .planning(
      keyword: PlanningKeyword(rawValue: keyword)!, timestamp: timestamp),
    file: file, line: line)
}

func evalSetting(
  _ str: String, key: String, value: String?,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .setting(key: key, value: value),
    file: file, line: line)
}

func evalBlank(
  _ str: String, rawIsNil: Bool = false,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .blank,
    file: file, line: line)
}

func evalLine(
  _ str: String, text: String,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .line(text: text),
    file: file, line: line)
}

func evalDrawerBegin(
  _ str: String, name: String,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .drawerBegin(name: name),
    file: file, line: line)
}

func evalDrawerEnd(
  _ str: String,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .drawerEnd,
    file: file, line: line)
}

func evalFootnote(
  _ str: String, label: String, content: String?,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .footnote(label: label, content: content),
    file: file, line: line)
}

func evalTableRow(
  _ str: String, cells: [String],
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .tableRow(cells: cells),
    file: file, line: line)
}

func evalHorizontalSeparator(
  _ str: String,
  file: StaticString = #file, line: UInt = #line
) {
  let token = Lexer.tokenize(line: str)
  expect(
    token!, toBe: .horizontalSeparator,
    file: file, line: line)
}
